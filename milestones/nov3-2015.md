# October 20th, 2015

## Accomplishments

### Feedback engines added

A feedback interface as added to define the base feedback engine, and then two engines were implemented using the interface
The audio engine and the haptic engine.

Each interface has a left, right and straight(x) method, which are designed to be used interchangable based on which engine the user is currently using

### Prototype of another mapping engine 

A prototype of a finger tracing on a map as a navigiational system. This approach looks promising and could be a good choice for the final product.

The prototype is a simple collision tracking of your finger on a map, allowing a blind user to feel where obstacles are

To make this a viable method the following is still needed to be implemented
* 2d mapping based on the users heading and position in a floorplan, when the user pivots, the map should also pivot
* user should be able to move through the floor plan map naturally 
* how to define the location where the user should get to, 
* as the user traces their finger to the destination, a unique pulse could occur, different than the original pulse type

Class diagram has been updated to reflect correct dependencies and
additional dependencies on the gravity sensor and magnetometer

## Challenges

We need a way to define floor maps before we can take the finger tracing mapping concept further.
we will need to do this before we can implement the full 2d tracing

## Research

A company called indoor atlas is using "sensor fusion" to improve their indoor 3d tracking, they use all available sensors on a device to track people very accuratly indoors.
It is possible we could adapt their concept of using radio signals and wifi signals to aid in positioning, along with the ibeacon.

[Link to indoor atlas](https://www.indooratlas.com/)

## For next week

Implement the feedback system into our application
Improvements to tracking/heading system disussed previous week
* 
*
*
*

